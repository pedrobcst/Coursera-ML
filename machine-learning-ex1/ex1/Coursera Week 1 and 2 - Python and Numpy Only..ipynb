{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will implement the regressions methods discussed in Week 1 and 2 by the Course of Andrew Ng.\n",
    "We will focus on the more general method, instead of the linear only(only one feature), since the focus will be the veterozation of the equations, and use the power of NumPy to easily calculate it. We will plot the data though.\n",
    "So instead of using $h_\\theta(x) = \\theta_{0} + \\theta_{1}x_{1}$ we will always use the more general form, $h_\\theta(x) = \\sum_{j=0}^{j=n} \\theta_{j}x_{j}$ where j is the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let us remind first about the definition of the cost function. Altough we gonna implement only the general form for j features, we will introduce here as for only one, and them generalize. This is because it is easy to see when we are dealing with only a straight line the intuition of the cost function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function $J(\\theta)$ (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost function is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J(\\theta) = \\sum_{i=1}^{i=m} (h_{\\theta}(x^{(i)}) - y^{(i)})^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $x^{(i)}$ is our feature vector from the ith training sample. As remember that we are dealing with training sets, with the pairs (x,y) meaning that for the features x, we have the output y. We want to find the function h(x) that better maps this x->y, when we introduce a new unknown feature x, that gives us a good estimate for the value of y(good prediction). So the idea is to minimize the cost function, that tell us, for our given set of parameters $\\theta$ how good our function h(x) is to the real value y.\n",
    "\n",
    "Note: m is the number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets realize that, first this can see as two vectors multiplication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{i=m}(h_{\\theta}(x^{(i)}) - y^{(i)}))(h_{\\theta}(x^{(i)}) - y^{(i)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have two identical vectors where the ith component is giving by the difference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec{v}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "h_{\\theta}(x^{(1)}) - y^{(1)} \\\\\n",
    "h_{\\theta}(x^{(2)}) - y^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "h_{\\theta}(x^{(i)}) - y^{(i)}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember where $x^{(i)}$ is the feature (input) of the $i^{th}$ training example, and $y^{(i)}$ is the correct output/target of the $i^{th}$ training example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J(\\theta) = \\frac{1}{2m}\\vec{v}^{T}\\vec{v}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to minimize J to find the best values of $\\theta$ that betters predict the target of our training set, this can be done with the gradient descent algorithm. It is well described on the course, so here we will just write the algorithm:\n",
    "\n",
    "Repeat until converge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\theta_{j} = \\theta_{j} - \\frac{\\alpha}{m}\\frac{\\partial J(\\theta)}{\\partial \\theta_{j}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\alpha$ is called the learning rate. Is just the \"size\" of the step we take at each interaction. Note that $\\alpha$ should always be small enough to guarantee that we dont overshoot the minimun. For regression, our hypothesis function is written as:\n",
    "$h_\\theta(x^{(i)}) = \\sum_{j=0}^{j=n} \\theta_{j}x^i_{j}$ remembering that $x_{j}^{i}$ is the value of the j-th feature for the i-th training sample, so $\\frac{\\partial h}{\\partial \\theta_{j}} = x^{i}_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for our gradient descent, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\theta_{j} = \\theta_{j} - \\frac{\\alpha}{m}\\sum_{i=1}^{i=m}(h_{\\theta}(x^{(i)}) - y^{(i)})x^{(i)}_{j}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is only a two vector component multiplication again! But notice since we have the indices \"j\", this means that the j-th value of the vector $\\vec{\\theta}$ is giving by vector matrix, and $x^{(i)}_{j}$ is the j-th row of the matrix $\\textbf{X}$ where each row i  has the training example values for the training example j. in such way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\textbf{X} =\n",
    "\\begin{bmatrix}\n",
    "x_{0}^{(1)} & x_{0}^{(2)} & x_{0}^{(3)} & \\dots & x_{0}^{(m)}\\\\\n",
    "x_{1}^{(1)} & x_{1}^{(2)} & x_{1}^{(3)} & \\dots & x_{1}^{(m)} \\\\\n",
    "\\vdots & \\vdots & \\vdots  & \\vdots & \\vdots\\\\\n",
    "x_{n}^{(1)} & x_{n}^{(2)} & x_{n}^{(3)} & \\dots & x_{n}^{(m)}          \n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And $x_{0} = 1$ always. So we can just rewrite our gradient descent as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\theta = \\theta - \\frac{\\alpha}{m} \\textbf{X}^{T}\\vec{v}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our focus here will be implemeting these general forms. So we can do any kind of regression: polynomial, linear ... it will just depend how we build our features and matrix X. (for example with we want to do a quadratic fit only, we put all the values of the first column 1, and all the values of column 2 as input^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ex1data1.txt\",\"r\") as data:\n",
    "    values = data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.1101,17.592\\n5.5277,9.1302\\n8.5186,13.662\\n7.0032,11.854\\n5.8598,6.8233\\n8.3829,11.886\\n7.4764,4.3483\\n8.5781,12\\n6.4862,6.5987\\n5.0546,3.8166\\n5.7107,3.2522\\n14.164,15.505\\n5.734,3.1551\\n8.4084,7.2258\\n5.6407,0.71618\\n5.3794,3.5129\\n6.3654,5.3048\\n5.1301,0.56077\\n6.4296,3.6518\\n7.0708,5.3893\\n6.1891,3.1386\\n20.27,21.767\\n5.4901,4.263\\n6.3261,5.1875\\n5.5649,3.0825\\n18.945,22.638\\n12.828,13.501\\n10.957,7.0467\\n13.176,14.692\\n22.203,24.147\\n5.2524,-1.22\\n6.5894,5.9966\\n9.2482,12.134\\n5.8918,1.8495\\n8.2111,6.5426\\n7.9334,4.5623\\n8.0959,4.1164\\n5.6063,3.3928\\n12.836,10.117\\n6.3534,5.4974\\n5.4069,0.55657\\n6.8825,3.9115\\n11.708,5.3854\\n5.7737,2.4406\\n7.8247,6.7318\\n7.0931,1.0463\\n5.0702,5.1337\\n5.8014,1.844\\n11.7,8.0043\\n5.5416,1.0179\\n7.5402,6.7504\\n5.3077,1.8396\\n7.4239,4.2885\\n7.6031,4.9981\\n6.3328,1.4233\\n6.3589,-1.4211\\n6.2742,2.4756\\n5.6397,4.6042\\n9.3102,3.9624\\n9.4536,5.4141\\n8.8254,5.1694\\n5.1793,-0.74279\\n21.279,17.929\\n14.908,12.054\\n18.959,17.054\\n7.2182,4.8852\\n8.2951,5.7442\\n10.236,7.7754\\n5.4994,1.0173\\n20.341,20.992\\n10.136,6.6799\\n7.3345,4.0259\\n6.0062,1.2784\\n7.2259,3.3411\\n5.0269,-2.6807\\n6.5479,0.29678\\n7.5386,3.8845\\n5.0365,5.7014\\n10.274,6.7526\\n5.1077,2.0576\\n5.7292,0.47953\\n5.1884,0.20421\\n6.3557,0.67861\\n9.7687,7.5435\\n6.5159,5.3436\\n8.5172,4.2415\\n9.1802,6.7981\\n6.002,0.92695\\n5.5204,0.152\\n5.0594,2.8214\\n5.7077,1.8451\\n7.6366,4.2959\\n5.8707,7.2029\\n5.3054,1.9869\\n8.2934,0.14454\\n13.394,9.0551\\n5.4369,0.61705\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values # Lets check how the data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = values.split(\"\\n\") # lets clean these \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6.1101,17.592',\n",
       " '5.5277,9.1302',\n",
       " '8.5186,13.662',\n",
       " '7.0032,11.854',\n",
       " '5.8598,6.8233',\n",
       " '8.3829,11.886',\n",
       " '7.4764,4.3483',\n",
       " '8.5781,12',\n",
       " '6.4862,6.5987',\n",
       " '5.0546,3.8166',\n",
       " '5.7107,3.2522',\n",
       " '14.164,15.505',\n",
       " '5.734,3.1551',\n",
       " '8.4084,7.2258',\n",
       " '5.6407,0.71618',\n",
       " '5.3794,3.5129',\n",
       " '6.3654,5.3048',\n",
       " '5.1301,0.56077',\n",
       " '6.4296,3.6518',\n",
       " '7.0708,5.3893',\n",
       " '6.1891,3.1386',\n",
       " '20.27,21.767',\n",
       " '5.4901,4.263',\n",
       " '6.3261,5.1875',\n",
       " '5.5649,3.0825',\n",
       " '18.945,22.638',\n",
       " '12.828,13.501',\n",
       " '10.957,7.0467',\n",
       " '13.176,14.692',\n",
       " '22.203,24.147',\n",
       " '5.2524,-1.22',\n",
       " '6.5894,5.9966',\n",
       " '9.2482,12.134',\n",
       " '5.8918,1.8495',\n",
       " '8.2111,6.5426',\n",
       " '7.9334,4.5623',\n",
       " '8.0959,4.1164',\n",
       " '5.6063,3.3928',\n",
       " '12.836,10.117',\n",
       " '6.3534,5.4974',\n",
       " '5.4069,0.55657',\n",
       " '6.8825,3.9115',\n",
       " '11.708,5.3854',\n",
       " '5.7737,2.4406',\n",
       " '7.8247,6.7318',\n",
       " '7.0931,1.0463',\n",
       " '5.0702,5.1337',\n",
       " '5.8014,1.844',\n",
       " '11.7,8.0043',\n",
       " '5.5416,1.0179',\n",
       " '7.5402,6.7504',\n",
       " '5.3077,1.8396',\n",
       " '7.4239,4.2885',\n",
       " '7.6031,4.9981',\n",
       " '6.3328,1.4233',\n",
       " '6.3589,-1.4211',\n",
       " '6.2742,2.4756',\n",
       " '5.6397,4.6042',\n",
       " '9.3102,3.9624',\n",
       " '9.4536,5.4141',\n",
       " '8.8254,5.1694',\n",
       " '5.1793,-0.74279',\n",
       " '21.279,17.929',\n",
       " '14.908,12.054',\n",
       " '18.959,17.054',\n",
       " '7.2182,4.8852',\n",
       " '8.2951,5.7442',\n",
       " '10.236,7.7754',\n",
       " '5.4994,1.0173',\n",
       " '20.341,20.992',\n",
       " '10.136,6.6799',\n",
       " '7.3345,4.0259',\n",
       " '6.0062,1.2784',\n",
       " '7.2259,3.3411',\n",
       " '5.0269,-2.6807',\n",
       " '6.5479,0.29678',\n",
       " '7.5386,3.8845',\n",
       " '5.0365,5.7014',\n",
       " '10.274,6.7526',\n",
       " '5.1077,2.0576',\n",
       " '5.7292,0.47953',\n",
       " '5.1884,0.20421',\n",
       " '6.3557,0.67861',\n",
       " '9.7687,7.5435',\n",
       " '6.5159,5.3436',\n",
       " '8.5172,4.2415',\n",
       " '9.1802,6.7981',\n",
       " '6.002,0.92695',\n",
       " '5.5204,0.152',\n",
       " '5.0594,2.8214',\n",
       " '5.7077,1.8451',\n",
       " '7.6366,4.2959',\n",
       " '5.8707,7.2029',\n",
       " '5.3054,1.9869',\n",
       " '8.2934,0.14454',\n",
       " '13.394,9.0551',\n",
       " '5.4369,0.61705',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = values[:-1] # lets remove te final trailing space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6.1101,17.592',\n",
       " '5.5277,9.1302',\n",
       " '8.5186,13.662',\n",
       " '7.0032,11.854',\n",
       " '5.8598,6.8233',\n",
       " '8.3829,11.886',\n",
       " '7.4764,4.3483',\n",
       " '8.5781,12',\n",
       " '6.4862,6.5987',\n",
       " '5.0546,3.8166',\n",
       " '5.7107,3.2522',\n",
       " '14.164,15.505',\n",
       " '5.734,3.1551',\n",
       " '8.4084,7.2258',\n",
       " '5.6407,0.71618',\n",
       " '5.3794,3.5129',\n",
       " '6.3654,5.3048',\n",
       " '5.1301,0.56077',\n",
       " '6.4296,3.6518',\n",
       " '7.0708,5.3893',\n",
       " '6.1891,3.1386',\n",
       " '20.27,21.767',\n",
       " '5.4901,4.263',\n",
       " '6.3261,5.1875',\n",
       " '5.5649,3.0825',\n",
       " '18.945,22.638',\n",
       " '12.828,13.501',\n",
       " '10.957,7.0467',\n",
       " '13.176,14.692',\n",
       " '22.203,24.147',\n",
       " '5.2524,-1.22',\n",
       " '6.5894,5.9966',\n",
       " '9.2482,12.134',\n",
       " '5.8918,1.8495',\n",
       " '8.2111,6.5426',\n",
       " '7.9334,4.5623',\n",
       " '8.0959,4.1164',\n",
       " '5.6063,3.3928',\n",
       " '12.836,10.117',\n",
       " '6.3534,5.4974',\n",
       " '5.4069,0.55657',\n",
       " '6.8825,3.9115',\n",
       " '11.708,5.3854',\n",
       " '5.7737,2.4406',\n",
       " '7.8247,6.7318',\n",
       " '7.0931,1.0463',\n",
       " '5.0702,5.1337',\n",
       " '5.8014,1.844',\n",
       " '11.7,8.0043',\n",
       " '5.5416,1.0179',\n",
       " '7.5402,6.7504',\n",
       " '5.3077,1.8396',\n",
       " '7.4239,4.2885',\n",
       " '7.6031,4.9981',\n",
       " '6.3328,1.4233',\n",
       " '6.3589,-1.4211',\n",
       " '6.2742,2.4756',\n",
       " '5.6397,4.6042',\n",
       " '9.3102,3.9624',\n",
       " '9.4536,5.4141',\n",
       " '8.8254,5.1694',\n",
       " '5.1793,-0.74279',\n",
       " '21.279,17.929',\n",
       " '14.908,12.054',\n",
       " '18.959,17.054',\n",
       " '7.2182,4.8852',\n",
       " '8.2951,5.7442',\n",
       " '10.236,7.7754',\n",
       " '5.4994,1.0173',\n",
       " '20.341,20.992',\n",
       " '10.136,6.6799',\n",
       " '7.3345,4.0259',\n",
       " '6.0062,1.2784',\n",
       " '7.2259,3.3411',\n",
       " '5.0269,-2.6807',\n",
       " '6.5479,0.29678',\n",
       " '7.5386,3.8845',\n",
       " '5.0365,5.7014',\n",
       " '10.274,6.7526',\n",
       " '5.1077,2.0576',\n",
       " '5.7292,0.47953',\n",
       " '5.1884,0.20421',\n",
       " '6.3557,0.67861',\n",
       " '9.7687,7.5435',\n",
       " '6.5159,5.3436',\n",
       " '8.5172,4.2415',\n",
       " '9.1802,6.7981',\n",
       " '6.002,0.92695',\n",
       " '5.5204,0.152',\n",
       " '5.0594,2.8214',\n",
       " '5.7077,1.8451',\n",
       " '7.6366,4.2959',\n",
       " '5.8707,7.2029',\n",
       " '5.3054,1.9869',\n",
       " '8.2934,0.14454',\n",
       " '13.394,9.0551',\n",
       " '5.4369,0.61705']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = ','.join(values) # Now we get a nice single string with each training set seperated by commas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.1101,17.592,5.5277,9.1302,8.5186,13.662,7.0032,11.854,5.8598,6.8233,8.3829,11.886,7.4764,4.3483,8.5781,12,6.4862,6.5987,5.0546,3.8166,5.7107,3.2522,14.164,15.505,5.734,3.1551,8.4084,7.2258,5.6407,0.71618,5.3794,3.5129,6.3654,5.3048,5.1301,0.56077,6.4296,3.6518,7.0708,5.3893,6.1891,3.1386,20.27,21.767,5.4901,4.263,6.3261,5.1875,5.5649,3.0825,18.945,22.638,12.828,13.501,10.957,7.0467,13.176,14.692,22.203,24.147,5.2524,-1.22,6.5894,5.9966,9.2482,12.134,5.8918,1.8495,8.2111,6.5426,7.9334,4.5623,8.0959,4.1164,5.6063,3.3928,12.836,10.117,6.3534,5.4974,5.4069,0.55657,6.8825,3.9115,11.708,5.3854,5.7737,2.4406,7.8247,6.7318,7.0931,1.0463,5.0702,5.1337,5.8014,1.844,11.7,8.0043,5.5416,1.0179,7.5402,6.7504,5.3077,1.8396,7.4239,4.2885,7.6031,4.9981,6.3328,1.4233,6.3589,-1.4211,6.2742,2.4756,5.6397,4.6042,9.3102,3.9624,9.4536,5.4141,8.8254,5.1694,5.1793,-0.74279,21.279,17.929,14.908,12.054,18.959,17.054,7.2182,4.8852,8.2951,5.7442,10.236,7.7754,5.4994,1.0173,20.341,20.992,10.136,6.6799,7.3345,4.0259,6.0062,1.2784,7.2259,3.3411,5.0269,-2.6807,6.5479,0.29678,7.5386,3.8845,5.0365,5.7014,10.274,6.7526,5.1077,2.0576,5.7292,0.47953,5.1884,0.20421,6.3557,0.67861,9.7687,7.5435,6.5159,5.3436,8.5172,4.2415,9.1802,6.7981,6.002,0.92695,5.5204,0.152,5.0594,2.8214,5.7077,1.8451,7.6366,4.2959,5.8707,7.2029,5.3054,1.9869,8.2934,0.14454,13.394,9.0551,5.4369,0.61705'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_values = list(map(float,values.split(\",\")[::2])) # The X values will also be in pairs of two, so we just get them this way. remember we have to convert the strings to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.1101,\n",
       " 5.5277,\n",
       " 8.5186,\n",
       " 7.0032,\n",
       " 5.8598,\n",
       " 8.3829,\n",
       " 7.4764,\n",
       " 8.5781,\n",
       " 6.4862,\n",
       " 5.0546,\n",
       " 5.7107,\n",
       " 14.164,\n",
       " 5.734,\n",
       " 8.4084,\n",
       " 5.6407,\n",
       " 5.3794,\n",
       " 6.3654,\n",
       " 5.1301,\n",
       " 6.4296,\n",
       " 7.0708,\n",
       " 6.1891,\n",
       " 20.27,\n",
       " 5.4901,\n",
       " 6.3261,\n",
       " 5.5649,\n",
       " 18.945,\n",
       " 12.828,\n",
       " 10.957,\n",
       " 13.176,\n",
       " 22.203,\n",
       " 5.2524,\n",
       " 6.5894,\n",
       " 9.2482,\n",
       " 5.8918,\n",
       " 8.2111,\n",
       " 7.9334,\n",
       " 8.0959,\n",
       " 5.6063,\n",
       " 12.836,\n",
       " 6.3534,\n",
       " 5.4069,\n",
       " 6.8825,\n",
       " 11.708,\n",
       " 5.7737,\n",
       " 7.8247,\n",
       " 7.0931,\n",
       " 5.0702,\n",
       " 5.8014,\n",
       " 11.7,\n",
       " 5.5416,\n",
       " 7.5402,\n",
       " 5.3077,\n",
       " 7.4239,\n",
       " 7.6031,\n",
       " 6.3328,\n",
       " 6.3589,\n",
       " 6.2742,\n",
       " 5.6397,\n",
       " 9.3102,\n",
       " 9.4536,\n",
       " 8.8254,\n",
       " 5.1793,\n",
       " 21.279,\n",
       " 14.908,\n",
       " 18.959,\n",
       " 7.2182,\n",
       " 8.2951,\n",
       " 10.236,\n",
       " 5.4994,\n",
       " 20.341,\n",
       " 10.136,\n",
       " 7.3345,\n",
       " 6.0062,\n",
       " 7.2259,\n",
       " 5.0269,\n",
       " 6.5479,\n",
       " 7.5386,\n",
       " 5.0365,\n",
       " 10.274,\n",
       " 5.1077,\n",
       " 5.7292,\n",
       " 5.1884,\n",
       " 6.3557,\n",
       " 9.7687,\n",
       " 6.5159,\n",
       " 8.5172,\n",
       " 9.1802,\n",
       " 6.002,\n",
       " 5.5204,\n",
       " 5.0594,\n",
       " 5.7077,\n",
       " 7.6366,\n",
       " 5.8707,\n",
       " 5.3054,\n",
       " 8.2934,\n",
       " 13.394,\n",
       " 5.4369]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_values = list(map(float, values.split(\",\")[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.592,\n",
       " 9.1302,\n",
       " 13.662,\n",
       " 11.854,\n",
       " 6.8233,\n",
       " 11.886,\n",
       " 4.3483,\n",
       " 12.0,\n",
       " 6.5987,\n",
       " 3.8166,\n",
       " 3.2522,\n",
       " 15.505,\n",
       " 3.1551,\n",
       " 7.2258,\n",
       " 0.71618,\n",
       " 3.5129,\n",
       " 5.3048,\n",
       " 0.56077,\n",
       " 3.6518,\n",
       " 5.3893,\n",
       " 3.1386,\n",
       " 21.767,\n",
       " 4.263,\n",
       " 5.1875,\n",
       " 3.0825,\n",
       " 22.638,\n",
       " 13.501,\n",
       " 7.0467,\n",
       " 14.692,\n",
       " 24.147,\n",
       " -1.22,\n",
       " 5.9966,\n",
       " 12.134,\n",
       " 1.8495,\n",
       " 6.5426,\n",
       " 4.5623,\n",
       " 4.1164,\n",
       " 3.3928,\n",
       " 10.117,\n",
       " 5.4974,\n",
       " 0.55657,\n",
       " 3.9115,\n",
       " 5.3854,\n",
       " 2.4406,\n",
       " 6.7318,\n",
       " 1.0463,\n",
       " 5.1337,\n",
       " 1.844,\n",
       " 8.0043,\n",
       " 1.0179,\n",
       " 6.7504,\n",
       " 1.8396,\n",
       " 4.2885,\n",
       " 4.9981,\n",
       " 1.4233,\n",
       " -1.4211,\n",
       " 2.4756,\n",
       " 4.6042,\n",
       " 3.9624,\n",
       " 5.4141,\n",
       " 5.1694,\n",
       " -0.74279,\n",
       " 17.929,\n",
       " 12.054,\n",
       " 17.054,\n",
       " 4.8852,\n",
       " 5.7442,\n",
       " 7.7754,\n",
       " 1.0173,\n",
       " 20.992,\n",
       " 6.6799,\n",
       " 4.0259,\n",
       " 1.2784,\n",
       " 3.3411,\n",
       " -2.6807,\n",
       " 0.29678,\n",
       " 3.8845,\n",
       " 5.7014,\n",
       " 6.7526,\n",
       " 2.0576,\n",
       " 0.47953,\n",
       " 0.20421,\n",
       " 0.67861,\n",
       " 7.5435,\n",
       " 5.3436,\n",
       " 4.2415,\n",
       " 6.7981,\n",
       " 0.92695,\n",
       " 0.152,\n",
       " 2.8214,\n",
       " 1.8451,\n",
       " 4.2959,\n",
       " 7.2029,\n",
       " 1.9869,\n",
       " 0.14454,\n",
       " 9.0551,\n",
       " 0.61705]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X_values).reshape(97,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.1101],\n",
       "       [  5.5277],\n",
       "       [  8.5186],\n",
       "       [  7.0032],\n",
       "       [  5.8598],\n",
       "       [  8.3829],\n",
       "       [  7.4764],\n",
       "       [  8.5781],\n",
       "       [  6.4862],\n",
       "       [  5.0546],\n",
       "       [  5.7107],\n",
       "       [ 14.164 ],\n",
       "       [  5.734 ],\n",
       "       [  8.4084],\n",
       "       [  5.6407],\n",
       "       [  5.3794],\n",
       "       [  6.3654],\n",
       "       [  5.1301],\n",
       "       [  6.4296],\n",
       "       [  7.0708],\n",
       "       [  6.1891],\n",
       "       [ 20.27  ],\n",
       "       [  5.4901],\n",
       "       [  6.3261],\n",
       "       [  5.5649],\n",
       "       [ 18.945 ],\n",
       "       [ 12.828 ],\n",
       "       [ 10.957 ],\n",
       "       [ 13.176 ],\n",
       "       [ 22.203 ],\n",
       "       [  5.2524],\n",
       "       [  6.5894],\n",
       "       [  9.2482],\n",
       "       [  5.8918],\n",
       "       [  8.2111],\n",
       "       [  7.9334],\n",
       "       [  8.0959],\n",
       "       [  5.6063],\n",
       "       [ 12.836 ],\n",
       "       [  6.3534],\n",
       "       [  5.4069],\n",
       "       [  6.8825],\n",
       "       [ 11.708 ],\n",
       "       [  5.7737],\n",
       "       [  7.8247],\n",
       "       [  7.0931],\n",
       "       [  5.0702],\n",
       "       [  5.8014],\n",
       "       [ 11.7   ],\n",
       "       [  5.5416],\n",
       "       [  7.5402],\n",
       "       [  5.3077],\n",
       "       [  7.4239],\n",
       "       [  7.6031],\n",
       "       [  6.3328],\n",
       "       [  6.3589],\n",
       "       [  6.2742],\n",
       "       [  5.6397],\n",
       "       [  9.3102],\n",
       "       [  9.4536],\n",
       "       [  8.8254],\n",
       "       [  5.1793],\n",
       "       [ 21.279 ],\n",
       "       [ 14.908 ],\n",
       "       [ 18.959 ],\n",
       "       [  7.2182],\n",
       "       [  8.2951],\n",
       "       [ 10.236 ],\n",
       "       [  5.4994],\n",
       "       [ 20.341 ],\n",
       "       [ 10.136 ],\n",
       "       [  7.3345],\n",
       "       [  6.0062],\n",
       "       [  7.2259],\n",
       "       [  5.0269],\n",
       "       [  6.5479],\n",
       "       [  7.5386],\n",
       "       [  5.0365],\n",
       "       [ 10.274 ],\n",
       "       [  5.1077],\n",
       "       [  5.7292],\n",
       "       [  5.1884],\n",
       "       [  6.3557],\n",
       "       [  9.7687],\n",
       "       [  6.5159],\n",
       "       [  8.5172],\n",
       "       [  9.1802],\n",
       "       [  6.002 ],\n",
       "       [  5.5204],\n",
       "       [  5.0594],\n",
       "       [  5.7077],\n",
       "       [  7.6366],\n",
       "       [  5.8707],\n",
       "       [  5.3054],\n",
       "       [  8.2934],\n",
       "       [ 13.394 ],\n",
       "       [  5.4369]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.c_[np.ones(97), X] # insert a column of ones to X. So we have our vectorization of h(x), remembering that for first parameter all values are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.    ,   6.1101],\n",
       "       [  1.    ,   5.5277],\n",
       "       [  1.    ,   8.5186],\n",
       "       [  1.    ,   7.0032],\n",
       "       [  1.    ,   5.8598],\n",
       "       [  1.    ,   8.3829],\n",
       "       [  1.    ,   7.4764],\n",
       "       [  1.    ,   8.5781],\n",
       "       [  1.    ,   6.4862],\n",
       "       [  1.    ,   5.0546],\n",
       "       [  1.    ,   5.7107],\n",
       "       [  1.    ,  14.164 ],\n",
       "       [  1.    ,   5.734 ],\n",
       "       [  1.    ,   8.4084],\n",
       "       [  1.    ,   5.6407],\n",
       "       [  1.    ,   5.3794],\n",
       "       [  1.    ,   6.3654],\n",
       "       [  1.    ,   5.1301],\n",
       "       [  1.    ,   6.4296],\n",
       "       [  1.    ,   7.0708],\n",
       "       [  1.    ,   6.1891],\n",
       "       [  1.    ,  20.27  ],\n",
       "       [  1.    ,   5.4901],\n",
       "       [  1.    ,   6.3261],\n",
       "       [  1.    ,   5.5649],\n",
       "       [  1.    ,  18.945 ],\n",
       "       [  1.    ,  12.828 ],\n",
       "       [  1.    ,  10.957 ],\n",
       "       [  1.    ,  13.176 ],\n",
       "       [  1.    ,  22.203 ],\n",
       "       [  1.    ,   5.2524],\n",
       "       [  1.    ,   6.5894],\n",
       "       [  1.    ,   9.2482],\n",
       "       [  1.    ,   5.8918],\n",
       "       [  1.    ,   8.2111],\n",
       "       [  1.    ,   7.9334],\n",
       "       [  1.    ,   8.0959],\n",
       "       [  1.    ,   5.6063],\n",
       "       [  1.    ,  12.836 ],\n",
       "       [  1.    ,   6.3534],\n",
       "       [  1.    ,   5.4069],\n",
       "       [  1.    ,   6.8825],\n",
       "       [  1.    ,  11.708 ],\n",
       "       [  1.    ,   5.7737],\n",
       "       [  1.    ,   7.8247],\n",
       "       [  1.    ,   7.0931],\n",
       "       [  1.    ,   5.0702],\n",
       "       [  1.    ,   5.8014],\n",
       "       [  1.    ,  11.7   ],\n",
       "       [  1.    ,   5.5416],\n",
       "       [  1.    ,   7.5402],\n",
       "       [  1.    ,   5.3077],\n",
       "       [  1.    ,   7.4239],\n",
       "       [  1.    ,   7.6031],\n",
       "       [  1.    ,   6.3328],\n",
       "       [  1.    ,   6.3589],\n",
       "       [  1.    ,   6.2742],\n",
       "       [  1.    ,   5.6397],\n",
       "       [  1.    ,   9.3102],\n",
       "       [  1.    ,   9.4536],\n",
       "       [  1.    ,   8.8254],\n",
       "       [  1.    ,   5.1793],\n",
       "       [  1.    ,  21.279 ],\n",
       "       [  1.    ,  14.908 ],\n",
       "       [  1.    ,  18.959 ],\n",
       "       [  1.    ,   7.2182],\n",
       "       [  1.    ,   8.2951],\n",
       "       [  1.    ,  10.236 ],\n",
       "       [  1.    ,   5.4994],\n",
       "       [  1.    ,  20.341 ],\n",
       "       [  1.    ,  10.136 ],\n",
       "       [  1.    ,   7.3345],\n",
       "       [  1.    ,   6.0062],\n",
       "       [  1.    ,   7.2259],\n",
       "       [  1.    ,   5.0269],\n",
       "       [  1.    ,   6.5479],\n",
       "       [  1.    ,   7.5386],\n",
       "       [  1.    ,   5.0365],\n",
       "       [  1.    ,  10.274 ],\n",
       "       [  1.    ,   5.1077],\n",
       "       [  1.    ,   5.7292],\n",
       "       [  1.    ,   5.1884],\n",
       "       [  1.    ,   6.3557],\n",
       "       [  1.    ,   9.7687],\n",
       "       [  1.    ,   6.5159],\n",
       "       [  1.    ,   8.5172],\n",
       "       [  1.    ,   9.1802],\n",
       "       [  1.    ,   6.002 ],\n",
       "       [  1.    ,   5.5204],\n",
       "       [  1.    ,   5.0594],\n",
       "       [  1.    ,   5.7077],\n",
       "       [  1.    ,   7.6366],\n",
       "       [  1.    ,   5.8707],\n",
       "       [  1.    ,   5.3054],\n",
       "       [  1.    ,   8.2934],\n",
       "       [  1.    ,  13.394 ],\n",
       "       [  1.    ,   5.4369]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array(Y_values).reshape(97,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(2).reshape(2,1) # lets initilize theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17.592  ],\n",
       "       [  9.1302 ],\n",
       "       [ 13.662  ],\n",
       "       [ 11.854  ],\n",
       "       [  6.8233 ],\n",
       "       [ 11.886  ],\n",
       "       [  4.3483 ],\n",
       "       [ 12.     ],\n",
       "       [  6.5987 ],\n",
       "       [  3.8166 ],\n",
       "       [  3.2522 ],\n",
       "       [ 15.505  ],\n",
       "       [  3.1551 ],\n",
       "       [  7.2258 ],\n",
       "       [  0.71618],\n",
       "       [  3.5129 ],\n",
       "       [  5.3048 ],\n",
       "       [  0.56077],\n",
       "       [  3.6518 ],\n",
       "       [  5.3893 ],\n",
       "       [  3.1386 ],\n",
       "       [ 21.767  ],\n",
       "       [  4.263  ],\n",
       "       [  5.1875 ],\n",
       "       [  3.0825 ],\n",
       "       [ 22.638  ],\n",
       "       [ 13.501  ],\n",
       "       [  7.0467 ],\n",
       "       [ 14.692  ],\n",
       "       [ 24.147  ],\n",
       "       [ -1.22   ],\n",
       "       [  5.9966 ],\n",
       "       [ 12.134  ],\n",
       "       [  1.8495 ],\n",
       "       [  6.5426 ],\n",
       "       [  4.5623 ],\n",
       "       [  4.1164 ],\n",
       "       [  3.3928 ],\n",
       "       [ 10.117  ],\n",
       "       [  5.4974 ],\n",
       "       [  0.55657],\n",
       "       [  3.9115 ],\n",
       "       [  5.3854 ],\n",
       "       [  2.4406 ],\n",
       "       [  6.7318 ],\n",
       "       [  1.0463 ],\n",
       "       [  5.1337 ],\n",
       "       [  1.844  ],\n",
       "       [  8.0043 ],\n",
       "       [  1.0179 ],\n",
       "       [  6.7504 ],\n",
       "       [  1.8396 ],\n",
       "       [  4.2885 ],\n",
       "       [  4.9981 ],\n",
       "       [  1.4233 ],\n",
       "       [ -1.4211 ],\n",
       "       [  2.4756 ],\n",
       "       [  4.6042 ],\n",
       "       [  3.9624 ],\n",
       "       [  5.4141 ],\n",
       "       [  5.1694 ],\n",
       "       [ -0.74279],\n",
       "       [ 17.929  ],\n",
       "       [ 12.054  ],\n",
       "       [ 17.054  ],\n",
       "       [  4.8852 ],\n",
       "       [  5.7442 ],\n",
       "       [  7.7754 ],\n",
       "       [  1.0173 ],\n",
       "       [ 20.992  ],\n",
       "       [  6.6799 ],\n",
       "       [  4.0259 ],\n",
       "       [  1.2784 ],\n",
       "       [  3.3411 ],\n",
       "       [ -2.6807 ],\n",
       "       [  0.29678],\n",
       "       [  3.8845 ],\n",
       "       [  5.7014 ],\n",
       "       [  6.7526 ],\n",
       "       [  2.0576 ],\n",
       "       [  0.47953],\n",
       "       [  0.20421],\n",
       "       [  0.67861],\n",
       "       [  7.5435 ],\n",
       "       [  5.3436 ],\n",
       "       [  4.2415 ],\n",
       "       [  6.7981 ],\n",
       "       [  0.92695],\n",
       "       [  0.152  ],\n",
       "       [  2.8214 ],\n",
       "       [  1.8451 ],\n",
       "       [  4.2959 ],\n",
       "       [  7.2029 ],\n",
       "       [  1.9869 ],\n",
       "       [  0.14454],\n",
       "       [  9.0551 ],\n",
       "       [  0.61705]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[:2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.    ,   6.1101],\n",
       "       [  1.    ,   5.5277],\n",
       "       [  1.    ,   8.5186],\n",
       "       [  1.    ,   7.0032],\n",
       "       [  1.    ,   5.8598],\n",
       "       [  1.    ,   8.3829],\n",
       "       [  1.    ,   7.4764],\n",
       "       [  1.    ,   8.5781],\n",
       "       [  1.    ,   6.4862],\n",
       "       [  1.    ,   5.0546],\n",
       "       [  1.    ,   5.7107],\n",
       "       [  1.    ,  14.164 ],\n",
       "       [  1.    ,   5.734 ],\n",
       "       [  1.    ,   8.4084],\n",
       "       [  1.    ,   5.6407],\n",
       "       [  1.    ,   5.3794],\n",
       "       [  1.    ,   6.3654],\n",
       "       [  1.    ,   5.1301],\n",
       "       [  1.    ,   6.4296],\n",
       "       [  1.    ,   7.0708],\n",
       "       [  1.    ,   6.1891],\n",
       "       [  1.    ,  20.27  ],\n",
       "       [  1.    ,   5.4901],\n",
       "       [  1.    ,   6.3261],\n",
       "       [  1.    ,   5.5649],\n",
       "       [  1.    ,  18.945 ],\n",
       "       [  1.    ,  12.828 ],\n",
       "       [  1.    ,  10.957 ],\n",
       "       [  1.    ,  13.176 ],\n",
       "       [  1.    ,  22.203 ],\n",
       "       [  1.    ,   5.2524],\n",
       "       [  1.    ,   6.5894],\n",
       "       [  1.    ,   9.2482],\n",
       "       [  1.    ,   5.8918],\n",
       "       [  1.    ,   8.2111],\n",
       "       [  1.    ,   7.9334],\n",
       "       [  1.    ,   8.0959],\n",
       "       [  1.    ,   5.6063],\n",
       "       [  1.    ,  12.836 ],\n",
       "       [  1.    ,   6.3534],\n",
       "       [  1.    ,   5.4069],\n",
       "       [  1.    ,   6.8825],\n",
       "       [  1.    ,  11.708 ],\n",
       "       [  1.    ,   5.7737],\n",
       "       [  1.    ,   7.8247],\n",
       "       [  1.    ,   7.0931],\n",
       "       [  1.    ,   5.0702],\n",
       "       [  1.    ,   5.8014],\n",
       "       [  1.    ,  11.7   ],\n",
       "       [  1.    ,   5.5416],\n",
       "       [  1.    ,   7.5402],\n",
       "       [  1.    ,   5.3077],\n",
       "       [  1.    ,   7.4239],\n",
       "       [  1.    ,   7.6031],\n",
       "       [  1.    ,   6.3328],\n",
       "       [  1.    ,   6.3589],\n",
       "       [  1.    ,   6.2742],\n",
       "       [  1.    ,   5.6397],\n",
       "       [  1.    ,   9.3102],\n",
       "       [  1.    ,   9.4536],\n",
       "       [  1.    ,   8.8254],\n",
       "       [  1.    ,   5.1793],\n",
       "       [  1.    ,  21.279 ],\n",
       "       [  1.    ,  14.908 ],\n",
       "       [  1.    ,  18.959 ],\n",
       "       [  1.    ,   7.2182],\n",
       "       [  1.    ,   8.2951],\n",
       "       [  1.    ,  10.236 ],\n",
       "       [  1.    ,   5.4994],\n",
       "       [  1.    ,  20.341 ],\n",
       "       [  1.    ,  10.136 ],\n",
       "       [  1.    ,   7.3345],\n",
       "       [  1.    ,   6.0062],\n",
       "       [  1.    ,   7.2259],\n",
       "       [  1.    ,   5.0269],\n",
       "       [  1.    ,   6.5479],\n",
       "       [  1.    ,   7.5386],\n",
       "       [  1.    ,   5.0365],\n",
       "       [  1.    ,  10.274 ],\n",
       "       [  1.    ,   5.1077],\n",
       "       [  1.    ,   5.7292],\n",
       "       [  1.    ,   5.1884],\n",
       "       [  1.    ,   6.3557],\n",
       "       [  1.    ,   9.7687],\n",
       "       [  1.    ,   6.5159],\n",
       "       [  1.    ,   8.5172],\n",
       "       [  1.    ,   9.1802],\n",
       "       [  1.    ,   6.002 ],\n",
       "       [  1.    ,   5.5204],\n",
       "       [  1.    ,   5.0594],\n",
       "       [  1.    ,   5.7077],\n",
       "       [  1.    ,   7.6366],\n",
       "       [  1.    ,   5.8707],\n",
       "       [  1.    ,   5.3054],\n",
       "       [  1.    ,   8.2934],\n",
       "       [  1.    ,  13.394 ],\n",
       "       [  1.    ,   5.4369]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(X,y, theta):\n",
    "    v = np.dot(X,theta) - y\n",
    "    m = y.size\n",
    "    return (1/(2*m))*np.dot(v.T,v)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.072733877455669"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try to calculate the cost now, for theta = (0,0)\n",
    "computeCost(X,Y,theta)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is exactly what was expected by the course!\n",
    "def gradientDescent(X,y, theta, alpha, iterr):\n",
    "    m = y.size\n",
    "    v = np.dot(X,theta) - y\n",
    "    const = alpha/m\n",
    "    costs = np.zeros(iterr)\n",
    "    for i in range(iterr):\n",
    "        theta_temp = theta.copy() # simultanoes\n",
    "        theta_temp = theta_temp - const*(X.T@v)\n",
    "        theta = theta_temp\n",
    "        costs[i] = computeCost(X,y, theta)\n",
    "        v = np.dot(X,theta) - y # update new values of V at each interaction\n",
    "    return (costs, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(2).reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "costs, theta = gradientDescent(X,Y,theta,0.01,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.73719046,  5.93159357,  5.90115471, ...,  4.47697138,\n",
       "        4.47697138,  4.47697138])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.89578088],\n",
       "       [ 1.19303364]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = X@theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb08cf1cac8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis.scatter(X[:,1:], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb08d1a7a20>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(X[:,1:],Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = np.linspace(Y.min(), Y.max(), 100).reshape(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = theta[0,0] + theta[1,0]*vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb08cf1c780>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis.plot(f,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npCYMviQ18f+GmWq6NWLIwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb08d03a748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb08cf65048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
